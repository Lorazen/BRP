{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy.stats import chi2,norm\n",
    "from scipy.optimize import curve_fit\n",
    "import sys\n",
    "import csv\n",
    "import statistics\n",
    "import math\n",
    "import scipy.signal\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f0a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topo_info(filename, xdim, ydim, xoffset, yoffset, xlen, ylen): # Extracts informartion about the topography from an\n",
    "                                                                   # # ASCII file.\n",
    "    izfile = open(filename, 'r')                                   \n",
    "    heights = np.zeros((ydim,xdim), float) # Apparent heights.\n",
    "    n = 1\n",
    "    j = 0\n",
    "\n",
    "    for i in izfile:\n",
    "        if n>(13) and n<(14+ydim):\n",
    "            height_values = i.split()\n",
    "            height_values = [float(i) for i in height_values]\n",
    "            height_values.pop(0) # The first value of each row is number of the measurement, this removes it.\n",
    "            heights[j,:] = height_values\n",
    "            j += 1\n",
    "        \n",
    "        n += 1\n",
    "\n",
    "    heights = np.flip(heights,1) # Need to flip the array for the correct image because of the scanning direction.\n",
    "    \n",
    "    xpixels = np.arange(1,xdim+1)\n",
    "    ypixels = np.arange(ydim,0)\n",
    "    \n",
    "    x_pixel,y_pixel = np.meshgrid(xpixels,ypixels) # Coordinates in the form of pixels of the image.\n",
    "    \n",
    "    xcoords = np.linspace(0, xlen, xdim) \n",
    "    ycoords = np.linspace(0, ylen, ydim)\n",
    "    \n",
    "    x,y = np.meshgrid(xcoords,ycoords) # Coordinates in the correct dimensions but non relative to the starting position\n",
    "                                       # of the STM.\n",
    "    topoxrightedge = xoffset + xlen/2\n",
    "    topoxleftedge = xoffset - xlen/2\n",
    "    topoytopedge = yoffset + ylen/2\n",
    "    topoybotedge = yoffset - ylen/2\n",
    "    xcoords_real = np.linspace(topoxleftedge, topoxrightedge, xdim)\n",
    "    ycoords_real = np.linspace(topoytopedge, topoybotedge, ydim)\n",
    "    \n",
    "    x_real,y_real = np.meshgrid(xcoords_real,ycoords_real) # \"True\" coordinates that take the starting position of the stm\n",
    "                                                           # into account and are important for assigning the positions of the\n",
    "                                                           # I-Z curves.\n",
    "    return [heights, x, y, x_pixel, y_pixel, x_real, y_real]\n",
    "    \n",
    "def cross_image(im1, im2): # Correlates two images.\n",
    "    value = scipy.signal.correlate(im1, im2, mode='same')\n",
    "    return value\n",
    "\n",
    "def func(z, k, I_0): # The exponential function used to fit the I-Z curves.\n",
    "    z = [x*(-2*k) for x in z]\n",
    "    return I_0*np.exp(z)\n",
    "\n",
    "def surrmedian(image, cx, cy, w, h): # The function that finds the median of the surroundings of a suspected single-molecule.\n",
    "    mask = np.logical_and(((image[1][0,:][np.newaxis,:]-cx)/(w/2.))**2 + ((image[2][:,0][:,np.newaxis]-cy)/(h/2.))**2 > 1.,\n",
    "                          ((image[1][0,:][np.newaxis,:]-cx)/((w/2.)*1.5))**2 + ((image[2][:,0][:,np.newaxis]-cy)/\n",
    "                                                                                ((h/2.)*1.5))**2 < 1.)\n",
    "    median = np.median(image[0][mask])\n",
    "    return median\n",
    "    \n",
    "def findzero(image, cx, cy, w, h): # A function that was used to visualize which parts of a topography would be defined as\n",
    "                                   # zero height after the use of surrmedian.\n",
    "    masktest = (image[0] == surrmedian(image, cx, cy, w, h))\n",
    "    return image[1][masktest], image[2][masktest]\n",
    "\n",
    "def crude_ah(image, cx, cy, w, h): # Uses the information of the ellipse outlining the single-molecule that one wants\n",
    "                                          # the apparent height of to extract the apparent height via the crude method.\n",
    "    testmask = ((image[1][0,:][np.newaxis,:]-cx)/(w/4.))**2 + ((image[2][:,0][:,np.newaxis]-cy)/(h/4.))**2 <= 1.\n",
    "    raw_height = np.median(image[0][testmask])\n",
    "    rel_height = raw_height-surrmedian(image,cx,cy,w,h)\n",
    "    return rel_height\n",
    "\n",
    "def drift_calc(im1, im2, cx, cy, w, h): # The function that calculates the drift of topographies.\n",
    "    \n",
    "    g1 = np.gradient(im1[0]) # This is for the methods that use the magnitudes of the gradients of the topogrpahies.\n",
    "    g2 = np.gradient(im2[0])\n",
    "    m1 = np.sqrt(g1[0]**2 + g1[1]**2)\n",
    "    m2 = np.sqrt(g2[0]**2 + g2[1]**2)\n",
    "    \n",
    "    m1 -= np.mean(m1) # This is for the method that subtracts the mean of the magnitudes from the topography.\n",
    "    m2 -= np.mean(m2)\n",
    "    \n",
    "    #m1 = im1[0]/np.mean(im1[0]) # This is for the method that uses the normalized topographies.\n",
    "    #m2 = im2[0]/np.mean(im2[0])\n",
    "    \n",
    "    corr_sameimg = cross_image(m1,m1)\n",
    "    corr_img = cross_image(m1,m2)\n",
    "    \n",
    "    x_corr_same = im1[1][np.unravel_index(np.argmax(corr_sameimg), corr_sameimg.shape)]\n",
    "    y_corr_same = im1[2][np.unravel_index(np.argmax(corr_sameimg), corr_sameimg.shape)]\n",
    "    \n",
    "    x_corr = im1[1][np.unravel_index(np.argmax(corr_img), corr_img.shape)]\n",
    "    y_corr = im1[2][np.unravel_index(np.argmax(corr_img), corr_img.shape)]\n",
    "    \n",
    "    x_drift = x_corr_same-x_corr\n",
    "    y_drift = y_corr_same-y_corr\n",
    "    \n",
    "    return x_drift, y_drift\n",
    "\n",
    "def izcurves(filename, curvenumber, xline, points, topofilename, xdim, ydim, xoffset, yoffset, xlen, ylen):\n",
    "    # This function uses the ASCII file containing I-Z curves and the topo_info function to return all the data about the\n",
    "    # I-Z curves, decay constants and the mappings hereof.\n",
    "    izfile = open(filename, 'r')\n",
    "\n",
    "    distances = [] # A list of the distances of the tip that the tip goes through at each point.\n",
    "    currents_array = np.zeros((0, curvenumber), float) # An array of all current values (each row is the currents of\n",
    "                                                       # all points at one distance).\n",
    "    currents = [] # These will be the lists of currents per specific point.\n",
    "    n = 1\n",
    "\n",
    "    for i in izfile:\n",
    "        if n==xline:\n",
    "            xdata = i.split()\n",
    "            xdata.pop(0)\n",
    "            xdata.pop(-1) # Include this if the last current is each time a string saying \"averaged\". Otherwise exclude.\n",
    "            xdata = [float(i) for i in xdata]\n",
    "        if n==(xline+1):\n",
    "            ydata = i.split()\n",
    "            ydata.pop(0)\n",
    "            ydata.pop(-1) # Include this if the last current is each time a string saying \"averaged\".\n",
    "            ydata = [float(i) for i in ydata]\n",
    "        if n>(xline+1) and n<(points+xline+2):\n",
    "            distance_currents = i.split()\n",
    "            distance_currents.pop(-1) # Include this if the last current is each time a string saying \"averaged\".\n",
    "            distance_currents = [float(i) for i in distance_currents]\n",
    "            distances.append(distance_currents.pop(0))\n",
    "            currents_array = np.append(currents_array, np.array([distance_currents]), axis=0)\n",
    "\n",
    "        n+=1\n",
    "    \n",
    "    for i in range(curvenumber):\n",
    "        currents.append(currents_array[:,i])\n",
    "    \n",
    "    #plt.figure(dpi=150) # This code is able to be used to plot specific I-Z curves with the corresponding fits. \n",
    "    #for i in currents:\n",
    "    #    plt.plot(distances,i,linewidth=0.5, label='I-Z curve', color='orange')\n",
    "    #    popt, pcov = curve_fit(func, distances, i, p0=[6e9,5e-11])\n",
    "    #    plt.plot(distances,func(distances,*popt), label='Fit', color='blue')\n",
    "    #plt.legend()\n",
    "    #plt.ylabel('Current [A]')\n",
    "    #plt.xlabel('Distance [m]')\n",
    "    #plt.xlim(right=0.6e-9)\n",
    "    #plt.title('I-Z curve with an exponential fit')\n",
    "    #plt.show()\n",
    "    \n",
    "    def coordinates(I_Z_curve): # A function that returns the coordinates of a certain I-Z curve by using its index.\n",
    "        return [xdata[I_Z_curve],ydata[I_Z_curve]]\n",
    "\n",
    "    tempcoords = coordinates(0)\n",
    "    equal_points = []\n",
    "    positions = [] # All the positions that measurements get taken of in order\n",
    "    decay_constants = [] # Decay constants of the positions in order\n",
    "    decay_var = []\n",
    "    #plt.figure(dpi=150) # All the plt's from this one until the plt.show() are for plotting all the fully averaged I-Z curves\n",
    "                         # with their corresponding fits.\n",
    "    \n",
    "    for i in range(len(currents)):\n",
    "        if tempcoords == coordinates(i):\n",
    "            equal_points.append(currents[i])\n",
    "        else:\n",
    "            summed_currents = [sum(j) for j in zip(*equal_points)]\n",
    "            averaged_currents = [(j / len(equal_points)) for j in summed_currents]\n",
    "            #plt.plot(distances,averaged_currents,linewidth=0.5)\n",
    "            diff = []\n",
    "            for j in equal_points:\n",
    "                diff.append((j-averaged_currents)**2)\n",
    "            diffsum = np.sum(diff, axis=0)\n",
    "            var = diffsum/(len(equal_points)-1)\n",
    "            std = np.sqrt(var)\n",
    "            popt, pcov = curve_fit(func, distances, averaged_currents, sigma=std, p0=[6e9,5e-11])\n",
    "            decay_constants.append(popt[0])\n",
    "            decay_var.append(np.diag(pcov)[0])\n",
    "            #plt.errorbar(distances, averaged_currents, yerr = std, fmt='.', color='orange', ecolor='lightgray',\n",
    "                         #elinewidth=1, capsize=0, label='Averaged I-Z curves')\n",
    "            #plt.plot(distances,func(distances,*popt), color='blue', label='Fit') # This is a plot of the fits\n",
    "            equal_points = [currents[i]]\n",
    "            positions.append(tempcoords)\n",
    "    \n",
    "        tempcoords = coordinates(i)\n",
    "\n",
    "    # Add this once more after the for loop for the last position.\n",
    "    summed_currents = [sum(j) for j in zip(*equal_points)]\n",
    "    averaged_currents = [(j / len(equal_points)) for j in summed_currents]\n",
    "    diff = []\n",
    "    for j in equal_points:\n",
    "        diff.append((j-averaged_currents)**2)\n",
    "    diffsum = np.sum(diff, axis=0)\n",
    "    var = diffsum/(len(equal_points)-1)\n",
    "    std = np.sqrt(var)\n",
    "    equal_points = [currents[i]]\n",
    "    #plt.plot(distances,averaged_currents,linewidth=0.5)\n",
    "    popt, pcov = curve_fit(func, distances, averaged_currents, sigma=std, p0=[6e9,5e-11])\n",
    "    decay_constants.append(popt[0])\n",
    "    decay_var.append(np.diag(pcov)[0])\n",
    "    #plt.errorbar(distances, averaged_currents, yerr = std, fmt='.', color='orange', ecolor='lightgray', elinewidth=1,\n",
    "                 #capsize=0, label='Averaged I-Z curves')\n",
    "    #plt.plot(distances,func(distances,*popt), color='blue', label='Fit')\n",
    "    positions.append(tempcoords)\n",
    "    \n",
    "    #plt.ylabel('Current [A]')\n",
    "    #plt.xlabel('Distance [m]')\n",
    "    #plt.xlim(right=0.6e-9)\n",
    "    #plt.legend()\n",
    "    #plt.title('Fit of the average of all I-Z curves')\n",
    "    #plt.show()\n",
    "\n",
    "    xpositions = []\n",
    "    ypositions = []\n",
    "\n",
    "    for i in positions:\n",
    "        xpositions.append(i[0])\n",
    "        ypositions.append(i[1])\n",
    "        \n",
    "    xpositions_unique = list(dict.fromkeys(xpositions))\n",
    "    ypositions_unique = list(dict.fromkeys(ypositions))\n",
    "\n",
    "    x,y=np.meshgrid(xpositions_unique,ypositions_unique)\n",
    "    z=np.zeros(x.shape,dtype=float) # This will be the array representing the decay\n",
    "                                    # constants per point\n",
    "\n",
    "    for i in range(len(xpositions_unique)):\n",
    "        for j in range(len(ypositions_unique)):\n",
    "            z[i,j] = decay_constants[positions.index([x[i,j],y[i,j]])]\n",
    "\n",
    "    plt.figure() # This is mapping of the fully averaged decay constants without a topography under it.\n",
    "    p = plt.imshow(z, cmap='afmhot', extent =[x.max(), x.min(), y.min(), y.max()]) # Extent makes sure it shows in the actual\n",
    "    plt.colorbar(p)                                                                # coordinates. Can express axis in pixels if\n",
    "    plt.title('2D mapping of k')                                                   # it is removed.\n",
    "    plt.ylabel('y [m]')\n",
    "    plt.xlabel('x [m]')\n",
    "    plt.show()\n",
    "    \n",
    "    xpositions = []\n",
    "    ypositions = []\n",
    "\n",
    "    for i in positions:\n",
    "        xpositions.append(i[0])\n",
    "        ypositions.append(i[1])\n",
    "\n",
    "\n",
    "    topo = topo_info(topofilename, xdim, ydim, xoffset, yoffset, xlen, ylen)\n",
    "\n",
    "    plt.figure(dpi=150) # This plots the topography that the decay constants will be mapped over.\n",
    "    p = plt.imshow(topo[0], cmap='YlOrBr_r', extent =[topo[1].min(), topo[1].max(), topo[2].max(), topo[2].min()])\n",
    "    cbar = plt.colorbar(p)\n",
    "    cbar.set_label('Apparent height [m]')\n",
    "    plt.title('Topography')                                                              \n",
    "    plt.ylabel('y [m]')\n",
    "    plt.xlabel('x [m]')\n",
    "    plt.show()\n",
    "    \n",
    "    xpositions = np.array(xpositions)\n",
    "    ypositions = np.array(ypositions)\n",
    "    decay_constants = np.array(decay_constants)\n",
    "    decay_var = np.array(decay_var)\n",
    "    mask = np.logical_and(np.logical_and(topo[5].min()<=xpositions,xpositions<=topo[5].max()),\n",
    "                          np.logical_and(topo[6].min()<=ypositions,ypositions<=topo[6].max()))\n",
    "    decay_constants = decay_constants[mask]\n",
    "    decay_var = decay_var[mask]\n",
    "    \n",
    "    weights = 1/decay_var\n",
    "    weighted_av = np.sum(weights*decay_constants)/np.sum(weights)\n",
    "    error_weighted_av = np.sqrt(1/np.sum(weights))\n",
    "    print('Weighted average =',weighted_av,'+/-',error_weighted_av)\n",
    "    print('Minimum decay constant =',min(decay_constants))\n",
    "    print('Maximum decay constant =',max(decay_constants))\n",
    "    print('Maximum error of a decay constant =',np.sqrt(max(decay_var)))\n",
    "    \n",
    "    plt.figure(dpi=150) # This plots the decay constant mapping\n",
    "    p = plt.imshow(topo[0], cmap='YlOrBr_r', extent =[topo[5].min(), topo[5].max(), topo[6].min(), topo[6].max()])\n",
    "    pbar = plt.colorbar(p) \n",
    "    pbar.set_label('Apparent height [m]')\n",
    "    s = plt.scatter(xpositions[mask], ypositions[mask], c=decay_constants, cmap='winter', alpha=1, s=10)\n",
    "    sbar = plt.colorbar(s)  \n",
    "    sbar.set_label('Decay Constant')\n",
    "    plt.title('Decay constants mapping')                                                              \n",
    "    plt.ylabel('y [m]')\n",
    "    plt.xlabel('x [m]')\n",
    "    plt.show()\n",
    "    \n",
    "    for n in [0,7,6,5,4,3,2,1]: # This obtaines eight different mappings by each time using the n'th curve of all points.\n",
    "        counter = n\n",
    "        decay = []\n",
    "        decay_var = []\n",
    "    \n",
    "        for i in currents:\n",
    "            if (counter%8)==0:\n",
    "                popt2, pcov2 = curve_fit(func, distances, i, p0=[6e9,5e-11])\n",
    "                decay.append(popt2[0])\n",
    "                decay_var.append(np.diag(pcov2)[0])\n",
    "            counter += 1\n",
    "        \n",
    "        decay = np.array(decay)\n",
    "        decay_var = np.array(decay_var)\n",
    "        decay = decay[mask]\n",
    "        decay_var = decay_var[mask]\n",
    "        weights = 1/decay_var\n",
    "        weighted_av = np.sum(weights*decay)/np.sum(weights)\n",
    "        error_weighted_av = np.sqrt(1/np.sum(weights))\n",
    "        print('Weighted average =',weighted_av,'+/-',error_weighted_av)\n",
    "        print('Minimum decay constant =',min(decay))\n",
    "        print('Maximum decay constant =',max(decay))\n",
    "        print('Maximum error of a decay constant =',np.sqrt(max(decay_var)))\n",
    "        \n",
    "        plt.figure(dpi=150)\n",
    "        p = plt.imshow(topo[0], cmap='YlOrBr_r', extent =[topo[5].min(), topo[5].max(), topo[6].min(), topo[6].max()])\n",
    "        pbar = plt.colorbar(p) \n",
    "        pbar.set_label('Apparent height [m]')\n",
    "        s = plt.scatter(xpositions[mask], ypositions[mask], c=decay, cmap='winter', alpha=1, s=10)\n",
    "        sbar = plt.colorbar(s)  \n",
    "        sbar.set_label('Decay Constant')\n",
    "        plt.title('Decay constants mapping')                                                              \n",
    "        plt.ylabel('y [m]')\n",
    "        plt.xlabel('x [m]')\n",
    "        plt.show() \n",
    "    \n",
    "    evencount = 0\n",
    "    tempcur = []\n",
    "    tempcur1 = []\n",
    "    tempcur2 = []\n",
    "    decay1 = []\n",
    "    decay2 = []\n",
    "    decay1_var = []\n",
    "    decay2_var = []\n",
    "    \n",
    "    for i in currents: # This obtaines two mappings for each direction of measurement.\n",
    "                       # Namely the retracting and approaching ones.\n",
    "        if len(tempcur1)==4:\n",
    "            sumtempcur1 = [sum(j) for j in zip(*tempcur1)]\n",
    "            avtempcur1 = [(j / 4) for j in sumtempcur1]\n",
    "            diff = []\n",
    "            for j in tempcur1:\n",
    "                diff.append((j-avtempcur1)**2)\n",
    "            diffsum = np.sum(diff, axis=0)\n",
    "            var = diffsum/(len(tempcur1)-1)\n",
    "            std = np.sqrt(var)\n",
    "            popt3, pcov3 = curve_fit(func, distances, avtempcur1, sigma=std, p0=[6e9,5e-11])\n",
    "            #plt.figure(dpi=150) # This plot is used to depict retracting averaged I-Z curves with their corresponding fits.\n",
    "            #plt.errorbar(distances, avtempcur1, yerr = std, fmt='.', color='orange', ecolor='lightgray', elinewidth=1,\n",
    "            #             capsize=0, label='Averaged I-Z curves')\n",
    "            #plt.plot(distances,func(distances,*popt3), label='Fit')\n",
    "            #plt.legend()\n",
    "            #plt.ylabel('Current [A]')\n",
    "            #plt.xlabel('Distance [m]')\n",
    "            #plt.title('Fit of retracting averaged I-Z curves')\n",
    "            #plt.xlim(right=0.6e-9)\n",
    "            #plt.show()\n",
    "            decay1.append(popt3[0])\n",
    "            decay1_var.append(np.diag(pcov3)[0])\n",
    "            tempcur1 = []\n",
    "        if len(tempcur2)==4:\n",
    "            sumtempcur2 = [sum(j) for j in zip(*tempcur2)]\n",
    "            avtempcur2 = [(j / 4) for j in sumtempcur2]\n",
    "            diff = []\n",
    "            for j in tempcur2:\n",
    "                diff.append((j-avtempcur2)**2)\n",
    "            diffsum = np.sum(diff, axis=0)\n",
    "            var = diffsum/(len(tempcur2)-1)\n",
    "            std = np.sqrt(var)\n",
    "            popt4, pcov4 = curve_fit(func, distances, avtempcur2, sigma=std, p0=[6e9,5e-11])\n",
    "            decay2.append(popt4[0])\n",
    "            decay2_var.append(np.diag(pcov4)[0])\n",
    "            tempcur2 = []\n",
    "        if (evencount%2)==0:\n",
    "            tempcur1.append(i)\n",
    "        if (evencount%2)==1:\n",
    "            tempcur2.append(i)      \n",
    "        evencount += 1\n",
    "        \n",
    "    sumtempcur2 = [sum(j) for j in zip(*tempcur2)]\n",
    "    avtempcur2 = [(j / 4) for j in sumtempcur2]\n",
    "    diff = []\n",
    "    for i in tempcur2:\n",
    "        diff.append((i-avtempcur2)**2)\n",
    "    diffsum = np.sum(diff, axis=0)\n",
    "    var = diffsum/(len(tempcur2)-1)\n",
    "    std = np.sqrt(var)\n",
    "    popt4, pcov4 = curve_fit(func, distances, avtempcur2, sigma=std, p0=[6e9,5e-11])\n",
    "    decay2.append(popt4[0])\n",
    "    decay2_var.append(np.diag(pcov4)[0])\n",
    "    \n",
    "    decay1 = np.array(decay1)\n",
    "    decay2 = np.array(decay2)\n",
    "    decay1_var = np.array(decay1_var)\n",
    "    decay2_var = np.array(decay2_var)\n",
    "    decay1 = decay1[mask]\n",
    "    decay2 = decay2[mask]\n",
    "    decay1_var = decay1_var[mask]\n",
    "    decay2_var = decay2_var[mask]\n",
    "    \n",
    "    decay_island = []      # This part is to calculate the weighted average and its error in and outside the island for the\n",
    "    decay_island_var = []  # retracting averaged mapping.\n",
    "    decay_surr = []\n",
    "    decay_surr_var = []\n",
    "    for i in range(len(decay1)):\n",
    "        if i>50 and i<58:\n",
    "            decay_island.append(decay1[i])\n",
    "            decay_island_var.append(decay1_var[i])\n",
    "        if i>66 and i<76:\n",
    "            decay_island.append(decay1[i])\n",
    "            decay_island_var.append(decay1_var[i])\n",
    "        if i>82 and i<93:\n",
    "            decay_island.append(decay1[i])\n",
    "            decay_island_var.append(decay1_var[i])\n",
    "        if i>98 and i<108:\n",
    "            decay_island.append(decay1[i])\n",
    "            decay_island_var.append(decay1_var[i])\n",
    "        else:\n",
    "            decay_surr.append(decay1[i])\n",
    "            decay_surr_var.append(decay1_var[i])\n",
    "            \n",
    "    weights_island = 1/np.array(decay_island_var)\n",
    "    weighted_av_island = np.sum(weights_island*decay_island)/np.sum(weights_island)\n",
    "    error_weighted_av_island = np.sqrt(1/np.sum(weights_island))\n",
    "    weights_surr = 1/np.array(decay_surr_var)\n",
    "    weighted_av_surr = np.sum(weights_surr*decay_surr)/np.sum(weights_surr)\n",
    "    error_weighted_av_surr = np.sqrt(1/np.sum(weights_surr))\n",
    "    \n",
    "    print('Weighted average in the island =',weighted_av_island,'+/-',error_weighted_av_island)\n",
    "    print('Weighted average outside of the island =',weighted_av_surr,'+/-',error_weighted_av_surr)\n",
    "    \n",
    "    weights1 = 1/decay1_var\n",
    "    weighted_av1 = np.sum(weights1*decay1)/np.sum(weights1)\n",
    "    error_weighted_av1 = np.sqrt(1/np.sum(weights1))\n",
    "    weights2 = 1/decay2_var\n",
    "    weighted_av2 = np.sum(weights2*decay2)/np.sum(weights2)\n",
    "    error_weighted_av2 = np.sqrt(1/np.sum(weights2))\n",
    "    \n",
    "    print('Weighted average =',weighted_av1,'+/-',error_weighted_av1)\n",
    "    print('Minimum decay constant =',min(decay1))\n",
    "    print('Maximum decay constant =',max(decay1))\n",
    "    print('Maximum error of a decay constant =',np.sqrt(max(decay1_var)))\n",
    "        \n",
    "    plt.figure(dpi=150) # This plots the decay constant mapping of the retracting averaged I-Z curves.\n",
    "    p = plt.imshow(topo[0], cmap='YlOrBr_r', extent =[topo[5].min(), topo[5].max(), topo[6].min(), topo[6].max()])\n",
    "    pbar = plt.colorbar(p) \n",
    "    pbar.set_label('Apparent height [m]')\n",
    "    s = plt.scatter(xpositions[mask], ypositions[mask], c=decay1, cmap='winter', alpha=1, s=10)\n",
    "    sbar = plt.colorbar(s)  \n",
    "    sbar.set_label('Decay Constant')\n",
    "    plt.title('Retracting measurements')                                                              \n",
    "    plt.ylabel('y [m]')\n",
    "    plt.xlabel('x [m]')\n",
    "    plt.show() \n",
    "    \n",
    "    print('Weighted average =',weighted_av2,'+/-',error_weighted_av2)\n",
    "    print('Minimum decay constant =',min(decay2))\n",
    "    print('Maximum decay constant =',max(decay2))\n",
    "    print('Maximum error of a decay constant =',np.sqrt(max(decay2_var)))\n",
    "        \n",
    "    plt.figure(dpi=150) # This plots the decay constant mapping of the approaching averaged I-Z curves.\n",
    "    p = plt.imshow(topo[0], cmap='YlOrBr_r', extent =[topo[5].min(), topo[5].max(), topo[6].min(), topo[6].max()])\n",
    "    pbar = plt.colorbar(p) \n",
    "    pbar.set_label('Apparent height [m]')\n",
    "    s = plt.scatter(xpositions[mask], ypositions[mask], c=decay2, cmap='winter', alpha=1, s=10)\n",
    "    sbar = plt.colorbar(s)  \n",
    "    sbar.set_label('Decay Constant')\n",
    "    plt.title('Approaching measurements')                                                              \n",
    "    plt.ylabel('y [m]')\n",
    "    plt.xlabel('x [m]')\n",
    "    plt.show() \n",
    "    \n",
    "def twoDgaussian(mesh, offset, A, xo, yo, theta, sigma_x, sigma_y): # The 2D gaussian function used to fit the molecules.\n",
    "    x,y = mesh\n",
    "    a = (np.cos(theta)**2)/(2*sigma_x**2)+(np.sin(theta)**2)/(2*sigma_y**2)\n",
    "    b = (np.sin(2*theta))/(4*sigma_x**2)-(np.sin(2*theta))/(4*sigma_y**2)\n",
    "    c = (np.sin(theta)**2)/(2*sigma_x**2)+(np.cos(theta)**2)/(2*sigma_y**2)\n",
    "    gaus = offset+A*np.exp(-(a*(x-xo)**2+2*b*(x-xo)*(y-yo)+c*(y-yo)**2))\n",
    "    return gaus.ravel()\n",
    "\n",
    "def paraboloid(mesh, offset, A, xo, yo, b, c): # The paraboloid function used to fit the molecules.\n",
    "    x,y = mesh\n",
    "    z = (-((x-xo)**2)/(b**2)-((y-yo)**2)/(c**2)+offset)*A\n",
    "    z = z.clip(min=0)\n",
    "    return z.ravel()\n",
    "\n",
    "def TwoDfits(image, cx, cy, w, h): # This function returns all the information that is needed to plot the 3D topographies of the\n",
    "                                   # suspected single-molecule and the 2D fits of them. It also returns the information that is\n",
    "                                   # needed to extract the apparent heights from the fits with their errors.\n",
    "    mask = ((image[1][0,:][np.newaxis,:]-cx)/(w/2.))**2 + ((image[2][:,0][:,np.newaxis]-cy)/(h/2.))**2 <= 1.\n",
    "    xmask = (((image[1][0,:][np.newaxis,:]-cx)/(w/2.))**2 <= 1.).ravel()\n",
    "    ymask = (((image[2][:,0][:,np.newaxis]-cy)/(h/2.))**2 <= 1.).ravel()\n",
    "    Z = np.where(mask, image[0]-surrmedian(image, cx, cy, w, h), 0)\n",
    "    X = image[1]\n",
    "    Y = image[2]\n",
    "    popt, pcov = curve_fit(twoDgaussian, (X,Y), Z.ravel(), p0=[0, np.max(Z), cx, cy, 0, 0.5*w, 0.5*h])\n",
    "    popt2, pcov2 = curve_fit(paraboloid, (X,Y), Z.ravel(), p0=[1, 1e-9, cx, cy, 0.5*w, 0.5*h])\n",
    "    gaussfit_raw = twoDgaussian((X,Y), *popt)\n",
    "    gaussfit = gaussfit_raw.reshape(np.shape(image[1]))\n",
    "    parafit_raw = paraboloid((X,Y), *popt2)\n",
    "    parafit = parafit_raw.reshape(np.shape(image[1]))\n",
    "    \n",
    "    return Z, X, Y, gaussfit, parafit, popt, pcov, popt2, pcov2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a95585",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This function call returns all the previously mentioned information of the nickel sample.\n",
    "izcurves('ni-tip-cleaning_2022_06_08_11_34_55_356_curves.txt', 2048, 20, 301,\n",
    "         'ni-tip-cleaning_2022_06_08_11_34_55_356_crop.txt', 129, 54, 498.047e-9, -255.469e-9, 500e-9, 211e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be6a58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The following part of the code illustrates the tracking of the drift of the test series.\n",
    "\n",
    "mol_one = topo_info('testing_2020_03_06_21_41_12_604.txt', 116, 107, -58.109e-9, -74.180e-9, 9.06e-9, 8.36e-9)\n",
    "mol_two = topo_info('testing_2020_03_06_21_43_09_433.txt', 128, 128, -57.7e-9, -73.8e-9, 8e-9, 8e-9)\n",
    "mol_three = topo_info('testing_2020_03_06_21_49_15_227.txt', 128, 128, -57.7e-9, -68.2e-9, 8e-9, 8e-9)\n",
    "\n",
    "img_one = mol_one\n",
    "img_two = mol_two\n",
    "\n",
    "cx = 4.8e-9 # The x coordinate of the centre of the outline\n",
    "cy = 4.5e-9 # The y coordinate of the centre of the outline\n",
    "w = 2*2e-9 # The width of the outline\n",
    "h = 2*2e-9 # The height of the outline\n",
    "\n",
    "mol_one[0] -= surrmedian(mol_one, cx, cy, w, h)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "p = plt.imshow(mol_one[0], cmap='YlOrBr_r', extent =[mol_one[1].min(), mol_one[1].max(), mol_one[2].max(), mol_one[2].min()]) # afmhot too extreme here\n",
    "cbar = plt.colorbar(p)    \n",
    "cbar.set_label('Apparent height [m]')\n",
    "outline = Ellipse((cx, cy), w, h, color='b', fill=False)\n",
    "#outline2 = Ellipse((cx, cy), w*1.5, h*1.5, color='b', fill=False) # This is for illustrating the ring that was used for\n",
    "fig = plt.gcf()                                                    # defining a height of zero.\n",
    "ax = fig.gca()\n",
    "ax.add_patch(outline)\n",
    "#ax.add_patch(outline2)\n",
    "plt.title('Topography')                                                              \n",
    "plt.ylabel('y [m]')\n",
    "plt.xlabel('x [m]')\n",
    "plt.show()\n",
    "\n",
    "drift = drift_calc(img_one, img_two, cx, cy, w, h)\n",
    "\n",
    "cx = cx+drift[0]\n",
    "cy = cy+drift[1]\n",
    "\n",
    "mol_two[0] -= surrmedian(mol_two, cx, cy, w, h)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "p = plt.imshow(mol_two[0], cmap='YlOrBr_r', extent =[mol_two[1].min(), mol_two[1].max(), mol_two[2].max(), mol_two[2].min()]) # afmhot too extreme here\n",
    "cbar = plt.colorbar(p)  \n",
    "cbar.set_label('Apparent height [m]')\n",
    "outline = Ellipse((cx, cy), w, h, color='b', fill=False)\n",
    "fig = plt.gcf()\n",
    "ax = fig.gca()\n",
    "ax.add_patch(outline)\n",
    "plt.title('Topography 2')                                                          \n",
    "plt.ylabel('y [m]')\n",
    "plt.xlabel('x [m]')\n",
    "plt.show()\n",
    "\n",
    "img_one = mol_two\n",
    "img_two = mol_three\n",
    "\n",
    "drift = drift_calc(img_one, img_two, cx, cy, w, h)\n",
    "\n",
    "cx = cx+drift[0]\n",
    "cy = cy+drift[1]\n",
    "\n",
    "mol_three[0] -= surrmedian(mol_three, cx, cy, w, h)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "p = plt.imshow(mol_three[0], cmap='YlOrBr_r', extent =[mol_three[1].min(), mol_three[1].max(), mol_three[2].max(), mol_three[2].min()]) # afmhot too extreme here\n",
    "cbar = plt.colorbar(p) \n",
    "cbar.set_label('Apparent height [m]')\n",
    "outline = Ellipse((cx, cy), w, h, color='b', fill=False)\n",
    "fig = plt.gcf()\n",
    "ax = fig.gca()\n",
    "ax.add_patch(outline)\n",
    "plt.title('Topography 3')                                                              \n",
    "plt.ylabel('y [m]')\n",
    "plt.xlabel('x [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb1727",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The following part of the code illustrates the tracking of the drift of the training series.\n",
    "\n",
    "one = topo_info('testing_2022_02_11_05_48_46_290.txt', 512, 512, -1.8e-6, 1.8e-6, 300e-9, 300e-9)\n",
    "two = topo_info('testing_2022_02_11_06_23_46_730.txt', 512, 512, -1.8e-6, 1.8e-6, 300e-9, 300e-9)\n",
    "three = topo_info('testing_2022_02_11_06_58_47_170.txt', 512, 512, -1.8e-6, 1.8e-6, 300e-9, 300e-9)\n",
    "\n",
    "img_one = one\n",
    "img_two = two\n",
    "\n",
    "cx = 1.35e-7\n",
    "cy = 1.7e-7\n",
    "w = 0.4e-7\n",
    "h = 0.2e-7\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "p = plt.imshow(one[0], cmap='YlOrBr_r', extent =[one[1].min(), one[1].max(), one[2].max(), one[2].min()])\n",
    "cbar = plt.colorbar(p) \n",
    "cbar.set_label('Apparent height [m]')   \n",
    "outline = Ellipse((cx, cy), w, h, color='b', fill=False)\n",
    "fig = plt.gcf()\n",
    "ax = fig.gca()\n",
    "ax.add_patch(outline)\n",
    "plt.title('Topography 1')                                                              \n",
    "plt.ylabel('y [m]')\n",
    "plt.xlabel('x [m]')\n",
    "plt.show()\n",
    "\n",
    "drift = drift_calc(img_one, img_two, cx, cy, w, h)\n",
    "\n",
    "cx = cx+drift[0]\n",
    "cy = cy+drift[1]\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "p = plt.imshow(two[0], cmap='YlOrBr_r', extent =[two[1].min(), two[1].max(), two[2].max(), two[2].min()])\n",
    "cbar = plt.colorbar(p) \n",
    "cbar.set_label('Apparent height [m]')    \n",
    "outline = Ellipse((cx, cy), w, h, color='b', fill=False)\n",
    "fig = plt.gcf()\n",
    "ax = fig.gca()\n",
    "ax.add_patch(outline)\n",
    "plt.title('Topography 2')                                                              \n",
    "plt.ylabel('y [m]')\n",
    "plt.xlabel('x [m]')\n",
    "plt.show()\n",
    "\n",
    "img_one = two\n",
    "img_two = three\n",
    "\n",
    "drift = drift_calc(img_one, img_two, cx, cy, w, h)\n",
    "\n",
    "cx = cx+drift[0]\n",
    "cy = cy+drift[1]\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "p = plt.imshow(three[0], cmap='YlOrBr_r', extent =[three[1].min(), three[1].max(), three[2].max(), three[2].min()])\n",
    "cbar = plt.colorbar(p) \n",
    "cbar.set_label('Apparent height [m]')   \n",
    "outline = Ellipse((cx, cy), w, h, color='b', fill=False)\n",
    "fig = plt.gcf()\n",
    "ax = fig.gca()\n",
    "ax.add_patch(outline)\n",
    "plt.title('Topography 3')                                                              \n",
    "plt.ylabel('y [m]')\n",
    "plt.xlabel('x [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13957e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The following part of the code is for the illustration of the correlation steps.\n",
    "\n",
    "img_one = one\n",
    "img_two = two\n",
    "\n",
    "grad1 = np.gradient(img_one[0])\n",
    "grad2 = np.gradient(img_two[0])\n",
    "mag1 = np.sqrt(grad1[0]**2 + grad1[1]**2)\n",
    "mag2 = np.sqrt(grad2[0]**2 + grad2[1]**2)\n",
    "\n",
    "mag1 -= np.mean(mag1)\n",
    "mag2 -= np.mean(mag2)\n",
    "\n",
    "#mag1 = img_one[0]/np.mean(img_one[0]) # This is for the method that uses the normalized topographies.\n",
    "#mag2 = img_two[0]/np.mean(img_two[0])\n",
    "\n",
    "plt.figure(dpi=150) # A plot to illustrate what the operations on the topography look like.\n",
    "p = plt.imshow(mag1, cmap='YlOrBr_r', extent =[img_one[1].min(), img_one[1].max(), img_one[2].max(), img_one[2].min()])\n",
    "cbar = plt.colorbar(p) \n",
    "cbar.set_label('Magnitude')\n",
    "plt.title('Magnitude with subtraction')                                                              \n",
    "plt.ylabel('y [m]')\n",
    "plt.xlabel('x [m]')\n",
    "plt.show()\n",
    "\n",
    "corr_sameimg = cross_image(mag1,mag1)\n",
    "corr_img = cross_image(mag1,mag2)\n",
    "\n",
    "plt.figure(dpi=150) # A plot to illustrate autocorrelation.\n",
    "p = plt.imshow(corr_sameimg, cmap='Greys_r', extent =[img_one[1].min(), img_one[1].max(), img_one[2].max(), img_one[2].min()])\n",
    "cbar = plt.colorbar(p)\n",
    "cbar.set_label('Magnitude')\n",
    "plt.title('Autocorrelation')                                                              \n",
    "plt.ylabel('y [m]')\n",
    "plt.xlabel('x [m]')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=150) # A plot to illustrate cross-correlation.\n",
    "p = plt.imshow(corr_img, cmap='Greys_r', extent =[img_one[1].min(), img_one[1].max(), img_one[2].max(), img_one[2].min()])\n",
    "cbar = plt.colorbar(p)\n",
    "cbar.set_label('Magnitude')\n",
    "plt.title('Cross-correlation')                                                              \n",
    "plt.ylabel('y [m]')\n",
    "plt.xlabel('x [m]')\n",
    "plt.show()\n",
    "\n",
    "cx = 1.35e-7\n",
    "cy = 1.7e-7\n",
    "w = 0.4e-7\n",
    "h = 0.2e-7\n",
    "\n",
    "drift = drift_calc(img_one, img_two, cx, cy, w, h)\n",
    "\n",
    "print('Drift = (',drift[0],',',drift[1],')','m')\n",
    "print('Circle centre = (',cx+drift[0],',',cy+drift[1],')','m')\n",
    "\n",
    "# These are the apparent heights as calculated by the crude method.\n",
    "\n",
    "ah1 = crude_ah(mol_one, 4.8e-9, 4.5e-9, 2*2e-9, 2*2e-9)\n",
    "ah2 = crude_ah(mol_two, 4.327304347826087e-09, 3.7113207547169807e-09, 2*2e-9, 2*2e-9)\n",
    "ah3 = crude_ah(mol_three, 6.1540760013693945e-09, 3.3333679988114687e-09, 2*2e-9, 2*2e-9)\n",
    "       \n",
    "meanah = (ah1+ah2+ah3)/3\n",
    "       \n",
    "unbiased_error = np.sqrt(np.sum(([ah1,ah2,ah3]-meanah)**2)/(3-1))\n",
    "standard_error = unbiased_error/np.sqrt(3)\n",
    "\n",
    "print('Apparent height of mol_one via the crude method =', ah1, '+/-', unbiased_error,'m')\n",
    "print('Apparent height of mol_two via the crude method =', ah2, '+/-', unbiased_error,'m')\n",
    "print('Apparent height of mol_three via the crude method =', ah3, '+/-', unbiased_error,'m')\n",
    "       \n",
    "print('Mean apparent height via the crude method =', meanah, '+/-', standard_error,'m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902e8e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The following part of the code is for the 3D plotting of the suspected single-molecule and the calculation of its apparent\n",
    "# height via 2D fitting.\n",
    "\n",
    "cx = 4.8e-9 # Coordinates for the first topography of the suspected single-molecule.\n",
    "cy = 4.5e-9\n",
    "w = 2*2e-9\n",
    "h = 2*2e-9\n",
    "\n",
    "drift = drift_calc(mol_one, mol_two, cx, cy, w, h)\n",
    "\n",
    "cx2 = cx+drift[0] # Coordinates for the second topography of the suspected single-molecule.\n",
    "cy2 = cy+drift[1]\n",
    "\n",
    "drift = drift_calc(mol_two, mol_three, cx2, cy2, w, h)\n",
    "\n",
    "cx3 = cx2+drift[0] # Coordinates for the third topography of the suspected single-molecule.\n",
    "cy3 = cy2+drift[1]\n",
    "\n",
    "fitting_one = TwoDfits(mol_one, cx, cy, w, h)\n",
    "fitting_two = TwoDfits(mol_two, cx2, cy2, w, h)\n",
    "fitting_three = TwoDfits(mol_three, cx3, cy3, w, h)\n",
    "\n",
    "fitting = fitting_one # Choose which topography to plot the topographies and fits of in the following plots.\n",
    "\n",
    "fig = plt.figure(dpi=150) # The plotting of the topography of the suspected single-molecule.\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(fitting[1], fitting[2], fitting[0], cmap='plasma')\n",
    "ax.view_init(30, 90) # Determines the perspective from which the plot is viewed.\n",
    "ax.set(xlabel='x [m]', ylabel='y [m]', zlabel='AH [m]')\n",
    "plt.title('First topography')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(dpi=150) # The plotting of the 2D gaussian fit of the topography of the suspected single-molecule.\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(fitting[1], fitting[2], fitting[3], cmap='plasma')\n",
    "ax.view_init(30, 90)\n",
    "ax.set(xlabel='x [m]', ylabel='y [m]', zlabel='AH [m]')\n",
    "plt.title('First fit')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(dpi=150) # The plotting of the paraboloid fit of the topography of the suspected single-molecule.\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(fitting[1], fitting[2], fitting[4], cmap='plasma')\n",
    "ax.view_init(30, 90)\n",
    "ax.set(xlabel='x [m]', ylabel='y [m]', zlabel='AH [m]')\n",
    "plt.title('Third fit')\n",
    "plt.show()\n",
    "\n",
    "print('Apparent height of mol_one via the gaussian fit =', np.max(fitting_one[3]), '+/-',\n",
    "      np.sqrt(np.diag(fitting_one[6])[1]),'m')\n",
    "print('Apparent height of mol_two via the gaussian fit =', np.max(fitting_two[3]), '+/-',\n",
    "      np.sqrt(np.diag(fitting_two[6])[1]),'m')\n",
    "print('Apparent height of mol_three via the gaussian fit =', np.max(fitting_three[3]), '+/-',\n",
    "      np.sqrt(np.diag(fitting_three[6])[1]),'m')\n",
    "weights = 1/np.array([np.diag(fitting_one[6])[1],np.diag(fitting_two[6])[1],np.diag(fitting_three[6])[1]])\n",
    "weighted_av = np.sum(weights*[np.max(fitting_one[3]),np.max(fitting_two[3]),np.max(fitting_three[3])])/np.sum(weights)\n",
    "weighted_av_er = np.sqrt(1/np.sum(weights))\n",
    "print('Weighted average of the apparent height via the gaussian fit =', weighted_av, '+/-', weighted_av_er,'m')\n",
    "print('Apparent height of mol_one via the paraboloid fit =', np.max(fitting_one[4]), '+/-',\n",
    "      np.sqrt(np.abs(np.diag(fitting_one[8])[1])),'m')\n",
    "print('Apparent height of mol_two via the paraboloid fit =', np.max(fitting_two[4]), '+/-',\n",
    "      np.sqrt(np.abs(np.diag(fitting_two[8])[1])),'m')\n",
    "print('Apparent height of mol_three via the paraboloid fit =', np.max(fitting_three[4]), '+/-',\n",
    "      np.sqrt(np.abs(np.diag(fitting_three[8])[1])),'m')\n",
    "weights = 1/np.array(np.abs([np.diag(fitting_one[8])[1],np.diag(fitting_two[8])[1],np.diag(fitting_three[8])[1]]))\n",
    "weighted_av = np.sum(weights*[np.max(fitting_one[4]),np.max(fitting_two[4]),np.max(fitting_three[4])])/np.sum(weights)\n",
    "weighted_av_er = np.sqrt(1/np.sum(weights))\n",
    "print('Weighted average of the apparent height via the paraboloid fit =', weighted_av, '+/-', weighted_av_er,'m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3d195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
